{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eyiGi6cPcpSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4LrXCGGuW0q",
        "outputId": "15056639-9b64-4acf-be4c-ca4859e906c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Audio_Project'...\n",
            "remote: Enumerating objects: 282, done.\u001b[K\n",
            "remote: Counting objects: 100% (282/282), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 282 (delta 152), reused 251 (delta 138), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (282/282), 3.19 MiB | 43.03 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://omertalmi5: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@github.com/omertalmi5/Audio_Project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Audio_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcENeUqxudPf",
        "outputId": "d34103cf-3321-4b6d-e480-f19279e8a489"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Audio_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fluent-speech-commands-dataset"
      ],
      "metadata": {
        "id": "U1i4eMPxjGQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy torch torchaudio torchvision wandb transformers librosa\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dymNfuCyuply",
        "outputId": "6918be3c-c19f-439a-9cae-75e6d9801c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the target directory\n",
        "# TARGET_DIR = \"/content/FluentSpeechCommands\"  # Change this to your desired directory\n",
        "# DATASET_URL = \"https://zenodo.org/record/4051654/files/fluent_speech_commands_dataset.zip\"\n",
        "\n",
        "# # Create the directory if it doesn't exist\n",
        "# import os\n",
        "# os.makedirs(TARGET_DIR, exist_ok=True)\n",
        "\n",
        "# # Download and extract the dataset\n",
        "# !wget -O \"$TARGET_DIR/fluent_speech_commands_dataset.zip\" \"$DATASET_URL\"\n",
        "# !unzip -q \"$TARGET_DIR/fluent_speech_commands_dataset.zip\" -d \"$TARGET_DIR\"\n",
        "# !rm \"$TARGET_DIR/fluent_speech_commands_dataset.zip\"\n",
        "\n",
        "# # Verify the dataset structure\n",
        "# !ls \"$TARGET_DIR\"\n",
        "\n"
      ],
      "metadata": {
        "id": "oUes5zgs5Y2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install s3prl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WuisBJvg79Ug",
        "outputId": "2d258f5d-5be0-4c0e-a97e-9df0d82d1b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "a2292936c4fa48a392fcab54a1c1ba85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting s3prl',\n",
              " '  Downloading s3prl-0.4.17.tar.gz (650 kB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/650.4 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m645.1/650.4 kB\\x1b[0m \\x1b[31m23.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m650.4/650.4 kB\\x1b[0m \\x1b[31m15.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h  Preparing metadata (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " 'Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from s3prl) (2.5.1+cu124)',\n",
              " 'Requirement already satisfied: torch!=1.10.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from s3prl) (2.5.1+cu124)',\n",
              " 'Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.11/dist-packages (from s3prl) (4.67.1)',\n",
              " 'Requirement already satisfied: numpy<2.0.0,>=1.21 in /usr/local/lib/python3.11/dist-packages (from s3prl) (1.26.4)',\n",
              " 'Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from s3prl) (6.0.2)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from s3prl) (3.17.0)',\n",
              " 'Collecting omegaconf>=2.1.1 (from s3prl)',\n",
              " '  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)',\n",
              " 'Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from s3prl) (75.1.0)',\n",
              " 'Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from s3prl) (2.32.3)',\n",
              " 'Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from s3prl) (4.48.3)',\n",
              " 'Requirement already satisfied: protobuf>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from s3prl) (4.25.6)',\n",
              " 'Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.1.1->s3prl)',\n",
              " '  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)',\n",
              " '\\x1b[?25l     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/117.0 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K     \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m117.0/117.0 kB\\x1b[0m \\x1b[31m10.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h  Preparing metadata (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " 'Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (4.12.2)',\n",
              " 'Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (3.4.2)',\n",
              " 'Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (3.1.5)',\n",
              " 'Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (2024.10.0)',\n",
              " 'Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (9.1.0.70)',\n",
              " 'Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.4.5.8)',\n",
              " 'Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (11.2.1.3)',\n",
              " 'Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (10.3.5.147)',\n",
              " 'Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (11.6.1.9)',\n",
              " 'Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.3.1.170)',\n",
              " 'Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (2.21.5)',\n",
              " 'Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.4.127)',\n",
              " 'Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (12.4.127)',\n",
              " 'Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (3.1.0)',\n",
              " 'Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=1.10.0,>=1.8.0->s3prl) (1.13.1)',\n",
              " 'Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=1.10.0,>=1.8.0->s3prl) (1.3.0)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->s3prl) (3.4.1)',\n",
              " 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->s3prl) (3.10)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->s3prl) (2.3.0)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->s3prl) (2025.1.31)',\n",
              " 'Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->s3prl) (0.28.1)',\n",
              " 'Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->s3prl) (24.2)',\n",
              " 'Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->s3prl) (2024.11.6)',\n",
              " 'Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->s3prl) (0.21.0)',\n",
              " 'Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->s3prl) (0.5.3)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=1.10.0,>=1.8.0->s3prl) (3.0.2)',\n",
              " 'Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/79.5 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m79.5/79.5 kB\\x1b[0m \\x1b[31m7.3 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hBuilding wheels for collected packages: s3prl, antlr4-python3-runtime',\n",
              " '  Building wheel for s3prl (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Created wheel for s3prl: filename=s3prl-0.4.17-py3-none-any.whl size=879927 sha256=923a554cfa54ea493401f55489211d4b9a42ea33ebefdccc0c8b06226297fa9c',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/85/c2/15/7a02361558ab1b2eeb7528ad50661b5d130d7cf93e43c15150',\n",
              " '  Building wheel for antlr4-python3-runtime (setup.py) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=2abcfe7d04bc44bc259fa637f3a24b71318c01096bc31acac8251d3d34576c4f',\n",
              " '  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1',\n",
              " 'Successfully built s3prl antlr4-python3-runtime',\n",
              " 'Installing collected packages: antlr4-python3-runtime, omegaconf, s3prl',\n",
              " 'Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0 s3prl-0.4.17']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from s3prl.dataio.corpus.fluent_speech_commands import FluentSpeechCommands\n",
        "\n",
        "# # Specify the target directory where the dataset will be saved\n",
        "# target_directory = \"/content/Audio_Project/dataset/FSC\"\n",
        "\n",
        "# # Download and unzip the dataset\n",
        "# FluentSpeechCommands.download_dataset(target_directory)\n",
        "\n",
        "# print(f\"Dataset downloaded and saved at {target_directory}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "U6NY5kTE7x6K",
        "outputId": "af7900ff-9976-47ed-a3af-67b148366493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Path.mkdir() got an unexpected keyword argument 'exists_ok'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d82019e25217>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Download and unzip the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mFluentSpeechCommands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset downloaded and saved at {target_directory}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/s3prl/dataio/corpus/fluent_speech_commands.py\u001b[0m in \u001b[0;36mdownload_dataset\u001b[0;34m(cls, tgt_dir)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtgt_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mtgt_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexists_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0munzip_targz_then_delete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Path.mkdir() got an unexpected keyword argument 'exists_ok'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio.datasets import FluentSpeechCommands\n"
      ],
      "metadata": {
        "id": "2T4v6kohAMqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = FluentSpeechCommands(root=\"/content/Audio_Project/dataset/FSC\", subset=\"train\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "GEwYCP2eAOIZ",
        "outputId": "68b7e6b8-de97-4950-b822-5b6adfe431a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset not found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-649fa19b7d9e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFluentSpeechCommands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/Audio_Project/dataset/FSC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchaudio/datasets/fluentcommands.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, subset)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msubset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{subset}_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://140.112.21.28:9000/fluent.tar.gz -O - | tar -xz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3lina0NDxsW",
        "outputId": "43f74af2-9f6e-4f80-9067-4210235b3a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-09 18:02:27--  http://140.112.21.28:9000/fluent.tar.gz\n",
            "Connecting to 140.112.21.28:9000... failed: Connection refused.\n",
            "\n",
            "gzip: stdin: unexpected end of file\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone -b fix_error_on_download https://github.com/omertalmi5/s3prl.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF5AJAlc_H4W",
        "outputId": "9fdafa3d-9dab-4e2c-d696-39334cca92e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 's3prl'...\n",
            "remote: Enumerating objects: 21244, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 21244 (delta 319), reused 240 (delta 233), pack-reused 20844 (from 4)\u001b[K\n",
            "Receiving objects: 100% (21244/21244), 125.64 MiB | 26.93 MiB/s, done.\n",
            "Resolving deltas: 100% (14473/14473), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd s3prl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihArZdlZ_Xhf",
        "outputId": "fc82d995-b4d8-4e73-db27-6d6a4591204b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/s3prl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pathlib import Path  # Explicitly import Path\n",
        "\n",
        "# # Set target directory\n",
        "# target_directory = Path(\"/content/Audio_Project/dataset/FSC\")\n",
        "\n",
        "# # Ensure the directory exists before downloading\n",
        "# target_directory.mkdir(parents=True, exist_ok=True)  # Correct syntax\n",
        "\n",
        "# # Download the dataset\n",
        "# from s3prl.dataio.corpus.fluent_speech_commands import FluentSpeechCommands\n",
        "# FluentSpeechCommands.download_dataset(target_directory)  # Convert to string if needed\n",
        "\n",
        "# print(f\"Dataset downloaded and saved at {target_directory}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "mcOCsIPE8sQL",
        "outputId": "13263ac6-0b9c-4b50-d9ab-d1e581481d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "HTTPConnectionPool(host='140.112.21.28', port=9000): Max retries exceeded with url: /fluent.tar.gz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b983f0580d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             sock = connection.create_connection(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             conn.request(\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tunnel_host\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Failed to establish a new connection: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7b983f0580d0>: Failed to establish a new connection: [Errno 111] Connection refused",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    842\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreason\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='140.112.21.28', port=9000): Max retries exceeded with url: /fluent.tar.gz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b983f0580d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e4f8c2a8a7cf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Download the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ms3prl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent_speech_commands\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFluentSpeechCommands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mFluentSpeechCommands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_directory\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to string if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset downloaded and saved at {target_directory}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/s3prl/s3prl/dataio/corpus/fluent_speech_commands.py\u001b[0m in \u001b[0;36mdownload_dataset\u001b[0;34m(cls, tgt_dir)\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[1;32m    161\u001b[0m         ):\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mdownload_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://140.112.21.28:9000/fluent.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         logger.info(\n\u001b[1;32m    164\u001b[0m             \u001b[0;34mf\"Fluent speech commands dataset downloaded. Located at {os.path.abspath(tgt_dir)}/fluent_speech_commands_dataset/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/s3prl/s3prl/dataio/corpus/fluent_speech_commands.py\u001b[0m in \u001b[0;36mdownload_from_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saving {filename} to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='140.112.21.28', port=9000): Max retries exceeded with url: /fluent.tar.gz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7b983f0580d0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --data_path TARGET_DIR --is_AST True --dataset_name 'FSC' --method 'adapter' --seq_or_par 'parallel' --reduction_rate_adapter 64 --adapter_type 'Pfeiffer' --apply_residual False --adapter_block 'conformer'"
      ],
      "metadata": {
        "id": "vDo_xKDYvIIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESC"
      ],
      "metadata": {
        "id": "vbfrEfeokT7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download the dataset using wget\n",
        "!wget -q --show-progress https://github.com/karoldvl/ESC-50/archive/master.zip -O dataset/ESC-50.zip"
      ],
      "metadata": {
        "id": "g7Q6T287u8PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9174fd-8140-4602-8c1d-b7cfaa865bfc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset/ESC-50.zip      [       <=>          ] 615.78M  14.3MB/s    in 40s     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Unzip the dataset\n",
        "!unzip -q  dataset/ESC-50.zip -d  dataset/ESC-50"
      ],
      "metadata": {
        "id": "7QEcPMxuk9jr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv dataset/ESC-50/ESC-50-master/* dataset/ESC-50/ && rm -r dataset/ESC-50/ESC-50-master\n"
      ],
      "metadata": {
        "id": "UtBFGh1_tsqb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: List extracted files to verify\n",
        "!ls  dataset/ESC-50/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZbZkcsjlAEQ",
        "outputId": "46dce20a-bfb2-40f6-d94e-a92f80465022"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio  esc50.gif  LICENSE  meta  pytest.ini  README.md\trequirements.txt  tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conformer Adapter Pfeiffer"
      ],
      "metadata": {
        "id": "XmD-eIx87kt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --data_path dataset/ --is_AST True --dataset_name 'ESC-50' --method 'adapter' --seq_or_par 'parallel' --reduction_rate_adapter 64 --adapter_type 'Pfeiffer' --apply_residual False --adapter_block 'conformer'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRRTGG7glhlw",
        "outputId": "a1a811ad-a1cf-4e94-f0ad-8caea0728dbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-14 09:33:24.751148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741944804.771384    1978 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741944804.777934    1978 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-14 09:33:24.799128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(data_path='dataset/', seed=10, device='cuda', num_workers=4, model_ckpt_AST='MIT/ast-finetuned-audioset-10-10-0.4593', model_ckpt_wav='facebook/wav2vec2-base-960h', max_len_audio=128000, save_best_ckpt=False, output_path='/checkpoints', is_AST=True, dataset_name='ESC-50', method='adapter', seq_or_par='parallel', reduction_rate_adapter=64, adapter_type='Pfeiffer', apply_residual=True, adapter_block='conformer', kernel_size=31, is_adapter_ablation=False, befafter='after', location='FFN', reduction_rate_moa=128, adapter_type_moa='Pfeiffer', location_moa='MHSA', adapter_module_moa='bottleneck', num_adapters=7, num_slots=1, normalize=False, reduction_rate_lora=64, alpha_lora=8, is_lora_ablation=False, lora_config='Wq,Wv', prompt_len_pt=24, prompt_len_prompt=25, is_deep_prompt=True, drop_prompt=0.0, is_few_shot_exp=False, few_shot_samples=64, use_wandb=False, project_name='', exp_name='', entity='')\n",
            "preprocessor_config.json: 100% 297/297 [00:00<00:00, 1.57MB/s]\n",
            "config.json: 100% 26.8k/26.8k [00:00<00:00, 80.0MB/s]\n",
            "model.safetensors: 100% 346M/346M [00:01<00:00, 278MB/s]\n",
            "Some weights of ASTModel_adapter were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_adapter were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 86111090\n",
            "Number of trainable params of the model: 423026\n",
            "AST_adapter(\n",
            "  (model): ASTModel_adapter(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_adapter(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_adapter(\n",
            "          (attention): ASTSdpaAttention(\n",
            "            (attention): ASTSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (adapter_module_FFN): Conformer_adapter(\n",
            "            (lnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (pwise_conv1): Conv1d(768, 24, kernel_size=(1,), stride=(1,))\n",
            "            (act1): GLU(dim=1)\n",
            "            (dwise_conv): Conv1d(12, 12, kernel_size=(31,), stride=(1,), padding=same, groups=12)\n",
            "            (bnorm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act2): SiLU()\n",
            "            (pwise_conv2): Conv1d(12, 768, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_adapter(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_adapter(\n",
            "        (attention): ASTSdpaAttention(\n",
            "          (attention): ASTSdpaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (adapter_module_FFN): Conformer_adapter(\n",
            "          (lnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (pwise_conv1): Conv1d(768, 24, kernel_size=(1,), stride=(1,))\n",
            "          (act1): GLU(dim=1)\n",
            "          (dwise_conv): Conv1d(12, 12, kernel_size=(31,), stride=(1,), padding=same, groups=12)\n",
            "          (bnorm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (act2): SiLU()\n",
            "          (pwise_conv2): Conv1d(12, 768, kernel_size=(1,), stride=(1,))\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 4.10027175200613\n",
            "Train intent accuracy:  1.8333333333333333\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004995066821070678\n",
            "Trainloss at epoch 1: 3.978646159172058\n",
            "Train intent accuracy:  1.25\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004980286753286194\n",
            "Trainloss at epoch 2: 3.946498394012451\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004955718126821718\n",
            "Trainloss at epoch 3: 3.9360573856454146\n",
            "Train intent accuracy:  1.5\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0049214579028215725\n",
            "Trainloss at epoch 4: 3.934432782624897\n",
            "Train intent accuracy:  1.5833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004877641290737876\n",
            "Trainloss at epoch 5: 3.9329093569203426\n",
            "Train intent accuracy:  1.5\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004824441214720621\n",
            "Trainloss at epoch 6: 3.9237795440774215\n",
            "Train intent accuracy:  1.7500000000000002\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004762067631165042\n",
            "Trainloss at epoch 7: 3.9282047874049137\n",
            "Train intent accuracy:  2.3333333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0046907667001096515\n",
            "Trainloss at epoch 8: 3.9305390496003\n",
            "Train intent accuracy:  1.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004610819813755028\n",
            "Trainloss at epoch 9: 3.9189332284425435\n",
            "Train intent accuracy:  1.6666666666666667\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004522542485937359\n",
            "Trainloss at epoch 10: 3.924386187603599\n",
            "Train intent accuracy:  1.9166666666666665\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0044262831069394664\n",
            "Trainloss at epoch 11: 3.9186900791368986\n",
            "Train intent accuracy:  2.25\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004322421568553524\n",
            "Trainloss at epoch 12: 3.9245576042878\n",
            "Train intent accuracy:  1.7500000000000002\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004211367764821718\n",
            "Trainloss at epoch 13: 3.925001433021144\n",
            "Train intent accuracy:  1.9166666666666665\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0040935599743717205\n",
            "Trainloss at epoch 14: 3.925426872153031\n",
            "Train intent accuracy:  1.0833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.00396946313073118\n",
            "Trainloss at epoch 15: 3.920994601751629\n",
            "Train intent accuracy:  1.0833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.003839566987447489\n",
            "Trainloss at epoch 16: 3.925107065000032\n",
            "Train intent accuracy:  1.4166666666666665\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.003704384185254285\n",
            "Trainloss at epoch 17: 3.918490874139886\n",
            "Train intent accuracy:  1.0833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.003564448228912676\n",
            "Trainloss at epoch 18: 3.9201678037643433\n",
            "Train intent accuracy:  2.166666666666667\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.003420311381711691\n",
            "Trainloss at epoch 19: 3.9223805603228117\n",
            "Train intent accuracy:  2.166666666666667\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0032725424859373652\n",
            "Trainloss at epoch 20: 3.921186930254886\n",
            "Train intent accuracy:  2.25\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.003121724717912136\n",
            "Trainloss at epoch 21: 3.9198848699268543\n",
            "Train intent accuracy:  1.5833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.00296845328646431\n",
            "Trainloss at epoch 22: 3.919576199431168\n",
            "Train intent accuracy:  1.25\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.002813333083910759\n",
            "Trainloss at epoch 23: 3.918557618793688\n",
            "Train intent accuracy:  1.9166666666666665\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0026569762988232814\n",
            "Trainloss at epoch 24: 3.9183960274646155\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0024999999999999966\n",
            "Trainloss at epoch 25: 3.91623582338032\n",
            "Train intent accuracy:  1.5833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.002343023701176713\n",
            "Trainloss at epoch 26: 3.918036184812847\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0021866669160892347\n",
            "Trainloss at epoch 27: 3.917187910330923\n",
            "Train intent accuracy:  1.0833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0020315467135356854\n",
            "Trainloss at epoch 28: 3.9148313999176025\n",
            "Train intent accuracy:  1.8333333333333333\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0018782752820878596\n",
            "Trainloss at epoch 29: 3.9156204085601005\n",
            "Train intent accuracy:  1.8333333333333333\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0017274575140626284\n",
            "Trainloss at epoch 30: 3.9155774743933427\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.001579688618288303\n",
            "Trainloss at epoch 31: 3.914687068838822\n",
            "Train intent accuracy:  1.4166666666666665\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0014355517710873164\n",
            "Trainloss at epoch 32: 3.9142875294936332\n",
            "Train intent accuracy:  1.25\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0012956158147457105\n",
            "Trainloss at epoch 33: 3.913883271970247\n",
            "Train intent accuracy:  1.5833333333333335\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0011604330125525072\n",
            "Trainloss at epoch 34: 3.913630667485689\n",
            "Train intent accuracy:  1.25\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0010305368692688165\n",
            "Trainloss at epoch 35: 3.9136257422597787\n",
            "Train intent accuracy:  1.5\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0009064400256282751\n",
            "Trainloss at epoch 36: 3.913307371892427\n",
            "Train intent accuracy:  1.5\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0007886322351782788\n",
            "Trainloss at epoch 37: 3.9129580008356193\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0006775784314464713\n",
            "Trainloss at epoch 38: 3.913271609105562\n",
            "Train intent accuracy:  1.5\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.000573716893060526\n",
            "Trainloss at epoch 39: 3.912817678953472\n",
            "Train intent accuracy:  1.4166666666666665\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.00047745751406263115\n",
            "Trainloss at epoch 40: 3.9124757490660014\n",
            "Train intent accuracy:  2.083333333333333\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0003891801862449619\n",
            "Trainloss at epoch 41: 3.912461054952521\n",
            "Train intent accuracy:  1.7500000000000002\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0003092332998903412\n",
            "Trainloss at epoch 42: 3.9122869905672575\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.00023793236883495124\n",
            "Trainloss at epoch 43: 3.9122573952925834\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.00017555878527937096\n",
            "Trainloss at epoch 44: 3.912191861554196\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.00012235870926211593\n",
            "Trainloss at epoch 45: 3.9121395976919877\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  7.854209717842218e-05\n",
            "Trainloss at epoch 46: 3.912139848658913\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  4.4281873178278385e-05\n",
            "Trainloss at epoch 47: 3.9120885510193673\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  1.9713246713805553e-05\n",
            "Trainloss at epoch 48: 3.91204077319095\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  4.933178929321093e-06\n",
            "Trainloss at epoch 49: 3.912038012554771\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0\n",
            "Some weights of ASTModel_adapter were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.0.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.1.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.10.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.11.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.2.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.3.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.4.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.5.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.6.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.7.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.8.adapter_module_FFN.pwise_conv2.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.num_batches_tracked', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.running_mean', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.running_var', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.bnorm.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.dwise_conv.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.dwise_conv.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.lnorm.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.lnorm.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv1.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv1.weight', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv2.bias', 'audio_spectrogram_transformer.encoder.layer.9.adapter_module_FFN.pwise_conv2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_adapter were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 86111090\n",
            "Number of trainable params of the model: 423026\n",
            "AST_adapter(\n",
            "  (model): ASTModel_adapter(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_adapter(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_adapter(\n",
            "          (attention): ASTSdpaAttention(\n",
            "            (attention): ASTSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (adapter_module_FFN): Conformer_adapter(\n",
            "            (lnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (pwise_conv1): Conv1d(768, 24, kernel_size=(1,), stride=(1,))\n",
            "            (act1): GLU(dim=1)\n",
            "            (dwise_conv): Conv1d(12, 12, kernel_size=(31,), stride=(1,), padding=same, groups=12)\n",
            "            (bnorm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act2): SiLU()\n",
            "            (pwise_conv2): Conv1d(12, 768, kernel_size=(1,), stride=(1,))\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_adapter(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_adapter(\n",
            "        (attention): ASTSdpaAttention(\n",
            "          (attention): ASTSdpaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (adapter_module_FFN): Conformer_adapter(\n",
            "          (lnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (pwise_conv1): Conv1d(768, 24, kernel_size=(1,), stride=(1,))\n",
            "          (act1): GLU(dim=1)\n",
            "          (dwise_conv): Conv1d(12, 12, kernel_size=(31,), stride=(1,), padding=same, groups=12)\n",
            "          (bnorm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (act2): SiLU()\n",
            "          (pwise_conv2): Conv1d(12, 768, kernel_size=(1,), stride=(1,))\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004995066821070678\n",
            "Trainloss at epoch 1: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004980286753286194\n",
            "Trainloss at epoch 2: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004955718126821718\n",
            "Trainloss at epoch 3: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0049214579028215725\n",
            "Trainloss at epoch 4: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004877641290737876\n",
            "Trainloss at epoch 5: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004824441214720621\n",
            "Trainloss at epoch 6: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004762067631165042\n",
            "Trainloss at epoch 7: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0046907667001096515\n",
            "Trainloss at epoch 8: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004610819813755028\n",
            "Trainloss at epoch 9: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004522542485937359\n",
            "Trainloss at epoch 10: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0044262831069394664\n",
            "Trainloss at epoch 11: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004322421568553524\n",
            "Trainloss at epoch 12: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.004211367764821718\n",
            "Trainloss at epoch 13: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.0040935599743717205\n",
            "Trainloss at epoch 14: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.00396946313073118\n",
            "Trainloss at epoch 15: nan\n",
            "Train intent accuracy:  2.0\n",
            "Valid intent accuracy:  2.0\n",
            "Learning rate after initialization:  0.003839566987447489\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vnlBTP1soIO",
        "outputId": "b82d2a67-1c15-4d63-ab56-a18368dac123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdataset/ESC-50.zip\u001b[m\n",
            "\t\u001b[31mdataset/ESC-50/\u001b[m\n",
            "\t\u001b[31mdataset/__pycache__/esc_50.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mdataset/__pycache__/fluentspeech.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mdataset/__pycache__/google_speech_commands_v2.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mdataset/__pycache__/iemocap.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mdataset/__pycache__/urban_sound_8k.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31msrc/__pycache__/AST.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31msrc/__pycache__/AST_LoRA.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31msrc/__pycache__/AST_adapters.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31msrc/__pycache__/AST_prompt_tuning.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31msrc/__pycache__/MoA.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31msrc/__pycache__/Wav2Vec_adapter.cpython-311.pyc\u001b[m\n",
            "\t\u001b[31mutils/__pycache__/engine.cpython-311.pyc\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear"
      ],
      "metadata": {
        "id": "AREvcsJS8j08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --data_path dataset/ --is_AST True --dataset_name 'ESC-50' --method 'linear'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjV8VbyvspFh",
        "outputId": "0d9f22b7-ce50-424f-d9ae-bca2e6b595ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-14 09:18:01.960247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741943881.981043   22623 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741943881.987460   22623 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-14 09:18:02.007734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(data_path='dataset/', seed=10, device='cuda', num_workers=4, model_ckpt_AST='MIT/ast-finetuned-audioset-10-10-0.4593', model_ckpt_wav='facebook/wav2vec2-base-960h', max_len_audio=128000, save_best_ckpt=False, output_path='/checkpoints', is_AST=True, dataset_name='ESC-50', method='linear', seq_or_par='parallel', reduction_rate_adapter=96, adapter_type='Pfeiffer', apply_residual=False, adapter_block='conformer', kernel_size=31, is_adapter_ablation=False, befafter='after', location='FFN', reduction_rate_moa=128, adapter_type_moa='Pfeiffer', location_moa='MHSA', adapter_module_moa='bottleneck', num_adapters=7, num_slots=1, normalize=False, reduction_rate_lora=64, alpha_lora=8, is_lora_ablation=False, lora_config='Wq,Wv', prompt_len_pt=24, prompt_len_prompt=25, is_deep_prompt=True, drop_prompt=0.0, is_few_shot_exp=False, few_shot_samples=64, use_wandb=False, project_name='', exp_name='', entity='')\n",
            "Some weights of ASTModel were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 85746482\n",
            "Number of trainable params of the model: 39986\n",
            "AST(\n",
            "  (model): ASTModel(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer(\n",
            "          (attention): ASTSdpaAttention(\n",
            "            (attention): ASTSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 3.5218912676761023\n",
            "Train intent accuracy:  15.166666666666668\n",
            "Valid intent accuracy:  36.25\n",
            "Learning rate after initialization:  0.000999013364214136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wx5m5SeV8DBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pref-T 24"
      ],
      "metadata": {
        "id": "F8gibcpbbVNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --data_path dataset/ --is_AST True --dataset_name 'ESC-50' --method 'prefix-tuning'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5ETGJbWbYnX",
        "outputId": "912fe204-1cd1-4b0f-a0c9-3e023a4a8e50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-14 16:30:56.931654: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741969856.952067     786 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741969856.958234     786 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-14 16:30:56.978803: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(data_path='dataset/', seed=10, device='cuda', num_workers=4, model_ckpt_AST='MIT/ast-finetuned-audioset-10-10-0.4593', model_ckpt_wav='facebook/wav2vec2-base-960h', max_len_audio=128000, save_best_ckpt=False, output_path='/checkpoints', is_AST=True, dataset_name='ESC-50', method='prefix-tuning', seq_or_par='parallel', reduction_rate_adapter=96, adapter_type='Pfeiffer', apply_residual=False, adapter_block='conformer', kernel_size=31, is_adapter_ablation=False, befafter='after', location='FFN', reduction_rate_moa=128, adapter_type_moa='Pfeiffer', location_moa='MHSA', adapter_module_moa='bottleneck', num_adapters=7, num_slots=1, normalize=False, reduction_rate_lora=64, alpha_lora=8, is_lora_ablation=False, lora_config='Wq,Wv', prompt_len_pt=24, prompt_len_prompt=25, is_deep_prompt=True, drop_prompt=0.0, is_few_shot_exp=False, few_shot_samples=64, use_wandb=False, project_name='', exp_name='', entity='')\n",
            "preprocessor_config.json: 100% 297/297 [00:00<00:00, 1.93MB/s]\n",
            "config.json: 100% 26.8k/26.8k [00:00<00:00, 96.1MB/s]\n",
            "model.safetensors: 100% 346M/346M [00:00<00:00, 364MB/s]\n",
            "Some weights of ASTModel_PT were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.value_tokens', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.key_tokens', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.value_tokens']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_PT were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 85967666\n",
            "Number of trainable params of the model: 261170\n",
            "AST_Prefix_tuning(\n",
            "  (model): ASTModel_PT(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_PT(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_PT(\n",
            "          (attention): ASTAttention_PT(\n",
            "            (attention): ASTSelfAttention_PT(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_PT(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_PT(\n",
            "        (attention): ASTAttention_PT(\n",
            "          (attention): ASTSelfAttention_PT(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 3.1750544435099552\n",
            "Train intent accuracy:  35.083333333333336\n",
            "Valid intent accuracy:  57.49999999999999\n",
            "Learning rate after initialization:  0.009990133642141356\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Audio_Project/main.py\", line 364, in <module>\n",
            "    main(args)\n",
            "  File \"/content/Audio_Project/main.py\", line 314, in main\n",
            "    train_loss, train_acc= train_one_epoch(model, train_loader, optimizer, scheduler, device, criterion)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Audio_Project/utils/engine.py\", line 31, in train_one_epoch\n",
            "    loss_batch.backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 522.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 18.12 MiB is free. Process 7981 has 14.72 GiB memory in use. Of the allocated memory 13.00 GiB is allocated by PyTorch, and 1.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWEvVe3SbxnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA"
      ],
      "metadata": {
        "id": "ggyWMQfwfG2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --data_path dataset/ --is_AST True --dataset_name 'ESC-50' --method 'LoRA'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUSXlP70fJJ7",
        "outputId": "19a9de9f-5d8c-48f3-9e15-68543f6f4c6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-14 16:35:25.199386: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-03-14 16:35:25.218224: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741970125.241022    1166 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741970125.247888    1166 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-14 16:35:25.270933: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(data_path='dataset/', seed=10, device='cuda', num_workers=4, model_ckpt_AST='MIT/ast-finetuned-audioset-10-10-0.4593', model_ckpt_wav='facebook/wav2vec2-base-960h', max_len_audio=128000, save_best_ckpt=False, output_path='/checkpoints', is_AST=True, dataset_name='ESC-50', method='LoRA', seq_or_par='parallel', reduction_rate_adapter=96, adapter_type='Pfeiffer', apply_residual=False, adapter_block='conformer', kernel_size=31, is_adapter_ablation=False, befafter='after', location='FFN', reduction_rate_moa=128, adapter_type_moa='Pfeiffer', location_moa='MHSA', adapter_module_moa='bottleneck', num_adapters=7, num_slots=1, normalize=False, reduction_rate_lora=64, alpha_lora=8, is_lora_ablation=False, lora_config='Wq,Wv', prompt_len_pt=24, prompt_len_prompt=25, is_deep_prompt=True, drop_prompt=0.0, is_few_shot_exp=False, few_shot_samples=64, use_wandb=False, project_name='', exp_name='', entity='')\n",
            "preprocessor_config.json: 100% 297/297 [00:00<00:00, 2.20MB/s]\n",
            "config.json: 100% 26.8k/26.8k [00:00<00:00, 84.9MB/s]\n",
            "model.safetensors: 100% 346M/346M [00:00<00:00, 483MB/s]\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_v.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 86188850\n",
            "Number of trainable params of the model: 482354\n",
            "AST_LoRA(\n",
            "  (model): ASTModel_LoRA(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_LoRA(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_LoRA(\n",
            "          (attention): ASTAttention_LoRA(\n",
            "            (attention): ASTSelfAttention_LoRA(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "              (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_LoRA(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_LoRA(\n",
            "        (attention): ASTAttention_LoRA(\n",
            "          (attention): ASTSelfAttention_LoRA(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "            (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 2.3762159708299135\n",
            "Train intent accuracy:  40.166666666666664\n",
            "Valid intent accuracy:  62.25000000000001\n",
            "Learning rate after initialization:  0.004995066821070678\n",
            "Trainloss at epoch 1: 0.6858370735457069\n",
            "Train intent accuracy:  79.0\n",
            "Valid intent accuracy:  73.75\n",
            "Learning rate after initialization:  0.004980286753286194\n",
            "Trainloss at epoch 2: 0.308928482234478\n",
            "Train intent accuracy:  89.16666666666667\n",
            "Valid intent accuracy:  78.0\n",
            "Learning rate after initialization:  0.004955718126821718\n",
            "Trainloss at epoch 3: 0.23904309460991308\n",
            "Train intent accuracy:  92.08333333333333\n",
            "Valid intent accuracy:  79.25\n",
            "Learning rate after initialization:  0.0049214579028215725\n",
            "Trainloss at epoch 4: 0.21513569428536453\n",
            "Train intent accuracy:  93.83333333333333\n",
            "Valid intent accuracy:  78.0\n",
            "Learning rate after initialization:  0.004877641290737876\n",
            "Trainloss at epoch 5: 0.17777281381974094\n",
            "Train intent accuracy:  94.91666666666667\n",
            "Valid intent accuracy:  81.25\n",
            "Learning rate after initialization:  0.004824441214720621\n",
            "Trainloss at epoch 6: 0.16679857183541907\n",
            "Train intent accuracy:  95.0\n",
            "Valid intent accuracy:  80.25\n",
            "Learning rate after initialization:  0.004762067631165042\n",
            "Trainloss at epoch 7: 0.14262801438177886\n",
            "Train intent accuracy:  95.91666666666666\n",
            "Valid intent accuracy:  80.75\n",
            "Learning rate after initialization:  0.0046907667001096515\n",
            "Trainloss at epoch 8: 0.1585424921879741\n",
            "Train intent accuracy:  95.41666666666667\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.004610819813755028\n",
            "Trainloss at epoch 9: 0.11780063807964325\n",
            "Train intent accuracy:  95.66666666666667\n",
            "Valid intent accuracy:  82.5\n",
            "Learning rate after initialization:  0.004522542485937359\n",
            "Trainloss at epoch 10: 0.091153598660113\n",
            "Train intent accuracy:  97.75\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.0044262831069394664\n",
            "Trainloss at epoch 11: 0.11256039020066198\n",
            "Train intent accuracy:  97.58333333333333\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  0.004322421568553524\n",
            "Trainloss at epoch 12: 0.1017039482800388\n",
            "Train intent accuracy:  97.25\n",
            "Valid intent accuracy:  79.75\n",
            "Learning rate after initialization:  0.004211367764821718\n",
            "Trainloss at epoch 13: 0.051060604777089076\n",
            "Train intent accuracy:  98.66666666666667\n",
            "Valid intent accuracy:  81.75\n",
            "Learning rate after initialization:  0.0040935599743717205\n",
            "Trainloss at epoch 14: 0.05518520114894368\n",
            "Train intent accuracy:  98.16666666666667\n",
            "Valid intent accuracy:  81.5\n",
            "Learning rate after initialization:  0.00396946313073118\n",
            "Trainloss at epoch 15: 0.09013546290072172\n",
            "Train intent accuracy:  97.25\n",
            "Valid intent accuracy:  81.75\n",
            "Learning rate after initialization:  0.003839566987447489\n",
            "Trainloss at epoch 16: 0.08326860009937694\n",
            "Train intent accuracy:  97.58333333333333\n",
            "Valid intent accuracy:  85.5\n",
            "Learning rate after initialization:  0.003704384185254285\n",
            "Trainloss at epoch 17: 0.0591010731571403\n",
            "Train intent accuracy:  97.58333333333333\n",
            "Valid intent accuracy:  85.0\n",
            "Learning rate after initialization:  0.003564448228912676\n",
            "Trainloss at epoch 18: 0.020319018941862804\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  86.0\n",
            "Learning rate after initialization:  0.003420311381711691\n",
            "Trainloss at epoch 19: 0.052010269354612226\n",
            "Train intent accuracy:  98.25\n",
            "Valid intent accuracy:  84.5\n",
            "Learning rate after initialization:  0.0032725424859373652\n",
            "Trainloss at epoch 20: 0.06346016824796893\n",
            "Train intent accuracy:  98.66666666666667\n",
            "Valid intent accuracy:  84.75\n",
            "Learning rate after initialization:  0.003121724717912136\n",
            "Trainloss at epoch 21: 0.024901801174947696\n",
            "Train intent accuracy:  99.33333333333333\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.00296845328646431\n",
            "Trainloss at epoch 22: 0.023867745770411074\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  85.75\n",
            "Learning rate after initialization:  0.002813333083910759\n",
            "Trainloss at epoch 23: 0.03730608126160836\n",
            "Train intent accuracy:  99.16666666666667\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.0026569762988232814\n",
            "Trainloss at epoch 24: 0.054882872855829955\n",
            "Train intent accuracy:  98.25\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.0024999999999999966\n",
            "Trainloss at epoch 25: 0.03572940167444023\n",
            "Train intent accuracy:  99.16666666666667\n",
            "Valid intent accuracy:  86.25\n",
            "Learning rate after initialization:  0.002343023701176713\n",
            "Trainloss at epoch 26: 0.01743451359614387\n",
            "Train intent accuracy:  99.5\n",
            "Valid intent accuracy:  85.75\n",
            "Learning rate after initialization:  0.0021866669160892347\n",
            "Trainloss at epoch 27: 0.023072269766616\n",
            "Train intent accuracy:  99.58333333333333\n",
            "Valid intent accuracy:  85.5\n",
            "Learning rate after initialization:  0.0020315467135356854\n",
            "Trainloss at epoch 28: 0.024224598653075333\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  87.0\n",
            "Learning rate after initialization:  0.0018782752820878596\n",
            "Trainloss at epoch 29: 0.018863382871801917\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.0017274575140626284\n",
            "Trainloss at epoch 30: 0.017414784668577148\n",
            "Train intent accuracy:  99.33333333333333\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.001579688618288303\n",
            "Trainloss at epoch 31: 0.02217784294579791\n",
            "Train intent accuracy:  99.58333333333333\n",
            "Valid intent accuracy:  87.0\n",
            "Learning rate after initialization:  0.0014355517710873164\n",
            "Trainloss at epoch 32: 0.003913263034758673\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.0012956158147457105\n",
            "Trainloss at epoch 33: 0.020297634434092816\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  85.75\n",
            "Learning rate after initialization:  0.0011604330125525072\n",
            "Trainloss at epoch 34: 0.01217179025115911\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.0010305368692688165\n",
            "Trainloss at epoch 35: 0.0060058735857877\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  0.0009064400256282751\n",
            "Trainloss at epoch 36: 0.010982817862225746\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.0007886322351782788\n",
            "Trainloss at epoch 37: 0.007902488159168953\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  87.25\n",
            "Learning rate after initialization:  0.0006775784314464713\n",
            "Trainloss at epoch 38: 0.012993328489277414\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.0\n",
            "Learning rate after initialization:  0.000573716893060526\n",
            "Trainloss at epoch 39: 0.003834522060443353\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  87.0\n",
            "Learning rate after initialization:  0.00047745751406263115\n",
            "Trainloss at epoch 40: 0.008625056122055915\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  0.0003891801862449619\n",
            "Trainloss at epoch 41: 0.0038325504857838447\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  0.0003092332998903412\n",
            "Trainloss at epoch 42: 0.014472154417154869\n",
            "Train intent accuracy:  99.58333333333333\n",
            "Valid intent accuracy:  89.0\n",
            "Learning rate after initialization:  0.00023793236883495124\n",
            "Trainloss at epoch 43: 0.004216526522022353\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  0.00017555878527937096\n",
            "Trainloss at epoch 44: 0.00847433578363914\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  0.00012235870926211593\n",
            "Trainloss at epoch 45: 0.001425521545139705\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  7.854209717842218e-05\n",
            "Trainloss at epoch 46: 0.0021147143572881376\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  4.4281873178278385e-05\n",
            "Trainloss at epoch 47: 0.0012636098334424834\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  1.9713246713805553e-05\n",
            "Trainloss at epoch 48: 0.0019325798758042143\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  4.933178929321093e-06\n",
            "Trainloss at epoch 49: 0.004228949340789481\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  0.0\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_v.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 86188850\n",
            "Number of trainable params of the model: 482354\n",
            "AST_LoRA(\n",
            "  (model): ASTModel_LoRA(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_LoRA(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_LoRA(\n",
            "          (attention): ASTAttention_LoRA(\n",
            "            (attention): ASTSelfAttention_LoRA(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "              (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_LoRA(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_LoRA(\n",
            "        (attention): ASTAttention_LoRA(\n",
            "          (attention): ASTSelfAttention_LoRA(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "            (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 2.3778866607891884\n",
            "Train intent accuracy:  38.83333333333333\n",
            "Valid intent accuracy:  69.0\n",
            "Learning rate after initialization:  0.004995066821070678\n",
            "Trainloss at epoch 1: 0.6622404738476402\n",
            "Train intent accuracy:  78.83333333333333\n",
            "Valid intent accuracy:  76.25\n",
            "Learning rate after initialization:  0.004980286753286194\n",
            "Trainloss at epoch 2: 0.36368227044218465\n",
            "Train intent accuracy:  88.58333333333334\n",
            "Valid intent accuracy:  80.0\n",
            "Learning rate after initialization:  0.004955718126821718\n",
            "Trainloss at epoch 3: 0.2681259414867351\n",
            "Train intent accuracy:  92.66666666666666\n",
            "Valid intent accuracy:  80.5\n",
            "Learning rate after initialization:  0.0049214579028215725\n",
            "Trainloss at epoch 4: 0.2488050990198788\n",
            "Train intent accuracy:  91.83333333333333\n",
            "Valid intent accuracy:  78.5\n",
            "Learning rate after initialization:  0.004877641290737876\n",
            "Trainloss at epoch 5: 0.19329874359659457\n",
            "Train intent accuracy:  94.58333333333333\n",
            "Valid intent accuracy:  79.0\n",
            "Learning rate after initialization:  0.004824441214720621\n",
            "Trainloss at epoch 6: 0.11404723997570966\n",
            "Train intent accuracy:  96.83333333333334\n",
            "Valid intent accuracy:  79.75\n",
            "Learning rate after initialization:  0.004762067631165042\n",
            "Trainloss at epoch 7: 0.13824946497027812\n",
            "Train intent accuracy:  95.75\n",
            "Valid intent accuracy:  78.5\n",
            "Learning rate after initialization:  0.0046907667001096515\n",
            "Trainloss at epoch 8: 0.10000938034959529\n",
            "Train intent accuracy:  97.08333333333333\n",
            "Valid intent accuracy:  81.25\n",
            "Learning rate after initialization:  0.004610819813755028\n",
            "Trainloss at epoch 9: 0.11892706714570522\n",
            "Train intent accuracy:  95.83333333333334\n",
            "Valid intent accuracy:  79.75\n",
            "Learning rate after initialization:  0.004522542485937359\n",
            "Trainloss at epoch 10: 0.1644664169044087\n",
            "Train intent accuracy:  95.25\n",
            "Valid intent accuracy:  80.25\n",
            "Learning rate after initialization:  0.0044262831069394664\n",
            "Trainloss at epoch 11: 0.09575416880512708\n",
            "Train intent accuracy:  97.33333333333334\n",
            "Valid intent accuracy:  81.75\n",
            "Learning rate after initialization:  0.004322421568553524\n",
            "Trainloss at epoch 12: 0.0795206016995699\n",
            "Train intent accuracy:  97.75\n",
            "Valid intent accuracy:  82.75\n",
            "Learning rate after initialization:  0.004211367764821718\n",
            "Trainloss at epoch 13: 0.06593032071893838\n",
            "Train intent accuracy:  98.58333333333333\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.0040935599743717205\n",
            "Trainloss at epoch 14: 0.05189677689984245\n",
            "Train intent accuracy:  98.33333333333333\n",
            "Valid intent accuracy:  78.75\n",
            "Learning rate after initialization:  0.00396946313073118\n",
            "Trainloss at epoch 15: 0.1035367569788114\n",
            "Train intent accuracy:  97.33333333333334\n",
            "Valid intent accuracy:  79.0\n",
            "Learning rate after initialization:  0.003839566987447489\n",
            "Trainloss at epoch 16: 0.07552221060215838\n",
            "Train intent accuracy:  98.0\n",
            "Valid intent accuracy:  81.5\n",
            "Learning rate after initialization:  0.003704384185254285\n",
            "Trainloss at epoch 17: 0.09095469888875653\n",
            "Train intent accuracy:  97.58333333333333\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.003564448228912676\n",
            "Trainloss at epoch 18: 0.05368266521193283\n",
            "Train intent accuracy:  98.66666666666667\n",
            "Valid intent accuracy:  81.75\n",
            "Learning rate after initialization:  0.003420311381711691\n",
            "Trainloss at epoch 19: 0.02815214014538613\n",
            "Train intent accuracy:  99.33333333333333\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.0032725424859373652\n",
            "Trainloss at epoch 20: 0.013552995450721172\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  82.75\n",
            "Learning rate after initialization:  0.003121724717912136\n",
            "Trainloss at epoch 21: 0.035890473843258074\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  81.25\n",
            "Learning rate after initialization:  0.00296845328646431\n",
            "Trainloss at epoch 22: 0.036921302472412786\n",
            "Train intent accuracy:  98.75\n",
            "Valid intent accuracy:  81.25\n",
            "Learning rate after initialization:  0.002813333083910759\n",
            "Trainloss at epoch 23: 0.051659679616262257\n",
            "Train intent accuracy:  98.66666666666667\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.0026569762988232814\n",
            "Trainloss at epoch 24: 0.047267897612121156\n",
            "Train intent accuracy:  98.66666666666667\n",
            "Valid intent accuracy:  82.75\n",
            "Learning rate after initialization:  0.0024999999999999966\n",
            "Trainloss at epoch 25: 0.01397324327569406\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  0.002343023701176713\n",
            "Trainloss at epoch 26: 0.018208671543489846\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  85.25\n",
            "Learning rate after initialization:  0.0021866669160892347\n",
            "Trainloss at epoch 27: 0.0145651540032735\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  85.75\n",
            "Learning rate after initialization:  0.0020315467135356854\n",
            "Trainloss at epoch 28: 0.03443740131287517\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  83.75\n",
            "Learning rate after initialization:  0.0018782752820878596\n",
            "Trainloss at epoch 29: 0.027515094437771233\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  84.5\n",
            "Learning rate after initialization:  0.0017274575140626284\n",
            "Trainloss at epoch 30: 0.017595596611499786\n",
            "Train intent accuracy:  99.58333333333333\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.001579688618288303\n",
            "Trainloss at epoch 31: 0.00545469918410833\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  85.0\n",
            "Learning rate after initialization:  0.0014355517710873164\n",
            "Trainloss at epoch 32: 0.005840962319205956\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.0012956158147457105\n",
            "Trainloss at epoch 33: 0.0098583508477436\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  86.25\n",
            "Learning rate after initialization:  0.0011604330125525072\n",
            "Trainloss at epoch 34: 0.012024493681996032\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  85.75\n",
            "Learning rate after initialization:  0.0010305368692688165\n",
            "Trainloss at epoch 35: 0.007036962936246327\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  86.0\n",
            "Learning rate after initialization:  0.0009064400256282751\n",
            "Trainloss at epoch 36: 0.006344032179760306\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.5\n",
            "Learning rate after initialization:  0.0007886322351782788\n",
            "Trainloss at epoch 37: 0.001742988943557353\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.0\n",
            "Learning rate after initialization:  0.0006775784314464713\n",
            "Trainloss at epoch 38: 0.007650103286371297\n",
            "Train intent accuracy:  99.58333333333333\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.000573716893060526\n",
            "Trainloss at epoch 39: 0.001535387342109492\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  0.00047745751406263115\n",
            "Trainloss at epoch 40: 0.0017843243855934002\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.0003891801862449619\n",
            "Trainloss at epoch 41: 0.009179338078722236\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.0003092332998903412\n",
            "Trainloss at epoch 42: 0.014326812938394906\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  0.00023793236883495124\n",
            "Trainloss at epoch 43: 0.0014321907340337546\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  0.00017555878527937096\n",
            "Trainloss at epoch 44: 0.0006772887281840667\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.5\n",
            "Learning rate after initialization:  0.00012235870926211593\n",
            "Trainloss at epoch 45: 0.012881096740832283\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  7.854209717842218e-05\n",
            "Trainloss at epoch 46: 0.0015709485906929906\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  4.4281873178278385e-05\n",
            "Trainloss at epoch 47: 0.0012836373942646834\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.5\n",
            "Learning rate after initialization:  1.9713246713805553e-05\n",
            "Trainloss at epoch 48: 0.0017503674500499312\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.75\n",
            "Learning rate after initialization:  4.933178929321093e-06\n",
            "Trainloss at epoch 49: 0.008989338451915262\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  88.75\n",
            "Learning rate after initialization:  0.0\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_v.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 86188850\n",
            "Number of trainable params of the model: 482354\n",
            "AST_LoRA(\n",
            "  (model): ASTModel_LoRA(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_LoRA(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_LoRA(\n",
            "          (attention): ASTAttention_LoRA(\n",
            "            (attention): ASTSelfAttention_LoRA(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "              (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_LoRA(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_LoRA(\n",
            "        (attention): ASTAttention_LoRA(\n",
            "          (attention): ASTSelfAttention_LoRA(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "            (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 2.415811173225704\n",
            "Train intent accuracy:  40.25\n",
            "Valid intent accuracy:  68.0\n",
            "Learning rate after initialization:  0.004995066821070678\n",
            "Trainloss at epoch 1: 0.7049256296534288\n",
            "Train intent accuracy:  79.0\n",
            "Valid intent accuracy:  73.75\n",
            "Learning rate after initialization:  0.004980286753286194\n",
            "Trainloss at epoch 2: 0.43288865940351234\n",
            "Train intent accuracy:  86.41666666666666\n",
            "Valid intent accuracy:  77.0\n",
            "Learning rate after initialization:  0.004955718126821718\n",
            "Trainloss at epoch 3: 0.22758981810980722\n",
            "Train intent accuracy:  92.91666666666667\n",
            "Valid intent accuracy:  74.75\n",
            "Learning rate after initialization:  0.0049214579028215725\n",
            "Trainloss at epoch 4: 0.21241572082630897\n",
            "Train intent accuracy:  93.5\n",
            "Valid intent accuracy:  77.25\n",
            "Learning rate after initialization:  0.004877641290737876\n",
            "Trainloss at epoch 5: 0.14633974080023013\n",
            "Train intent accuracy:  95.66666666666667\n",
            "Valid intent accuracy:  77.5\n",
            "Learning rate after initialization:  0.004824441214720621\n",
            "Trainloss at epoch 6: 0.12314225257815499\n",
            "Train intent accuracy:  96.66666666666667\n",
            "Valid intent accuracy:  77.25\n",
            "Learning rate after initialization:  0.004762067631165042\n",
            "Trainloss at epoch 7: 0.11892298378638531\n",
            "Train intent accuracy:  96.91666666666666\n",
            "Valid intent accuracy:  80.5\n",
            "Learning rate after initialization:  0.0046907667001096515\n",
            "Trainloss at epoch 8: 0.15608411622968943\n",
            "Train intent accuracy:  95.33333333333334\n",
            "Valid intent accuracy:  76.5\n",
            "Learning rate after initialization:  0.004610819813755028\n",
            "Trainloss at epoch 9: 0.10265146374800488\n",
            "Train intent accuracy:  96.91666666666666\n",
            "Valid intent accuracy:  77.25\n",
            "Learning rate after initialization:  0.004522542485937359\n",
            "Trainloss at epoch 10: 0.10865390222323568\n",
            "Train intent accuracy:  96.58333333333333\n",
            "Valid intent accuracy:  80.75\n",
            "Learning rate after initialization:  0.0044262831069394664\n",
            "Trainloss at epoch 11: 0.10471138448797558\n",
            "Train intent accuracy:  97.25\n",
            "Valid intent accuracy:  78.75\n",
            "Learning rate after initialization:  0.004322421568553524\n",
            "Trainloss at epoch 12: 0.10769560864489329\n",
            "Train intent accuracy:  97.25\n",
            "Valid intent accuracy:  79.5\n",
            "Learning rate after initialization:  0.004211367764821718\n",
            "Trainloss at epoch 13: 0.0662678482231537\n",
            "Train intent accuracy:  98.16666666666667\n",
            "Valid intent accuracy:  79.0\n",
            "Learning rate after initialization:  0.0040935599743717205\n",
            "Trainloss at epoch 14: 0.0840220550859445\n",
            "Train intent accuracy:  97.91666666666666\n",
            "Valid intent accuracy:  79.0\n",
            "Learning rate after initialization:  0.00396946313073118\n",
            "Trainloss at epoch 15: 0.0645354361959586\n",
            "Train intent accuracy:  98.16666666666667\n",
            "Valid intent accuracy:  80.0\n",
            "Learning rate after initialization:  0.003839566987447489\n",
            "Trainloss at epoch 16: 0.03435970037121718\n",
            "Train intent accuracy:  99.0\n",
            "Valid intent accuracy:  83.5\n",
            "Learning rate after initialization:  0.003704384185254285\n",
            "Trainloss at epoch 17: 0.04036225089313168\n",
            "Train intent accuracy:  99.0\n",
            "Valid intent accuracy:  81.75\n",
            "Learning rate after initialization:  0.003564448228912676\n",
            "Trainloss at epoch 18: 0.056380662442135965\n",
            "Train intent accuracy:  98.5\n",
            "Valid intent accuracy:  79.5\n",
            "Learning rate after initialization:  0.003420311381711691\n",
            "Trainloss at epoch 19: 0.06434372298137628\n",
            "Train intent accuracy:  98.83333333333333\n",
            "Valid intent accuracy:  79.75\n",
            "Learning rate after initialization:  0.0032725424859373652\n",
            "Trainloss at epoch 20: 0.07329504892511882\n",
            "Train intent accuracy:  97.83333333333334\n",
            "Valid intent accuracy:  78.0\n",
            "Learning rate after initialization:  0.003121724717912136\n",
            "Trainloss at epoch 21: 0.0444797883361676\n",
            "Train intent accuracy:  98.83333333333333\n",
            "Valid intent accuracy:  80.75\n",
            "Learning rate after initialization:  0.00296845328646431\n",
            "Trainloss at epoch 22: 0.036092022804567886\n",
            "Train intent accuracy:  99.33333333333333\n",
            "Valid intent accuracy:  81.75\n",
            "Learning rate after initialization:  0.002813333083910759\n",
            "Trainloss at epoch 23: 0.039587511772927096\n",
            "Train intent accuracy:  98.91666666666666\n",
            "Valid intent accuracy:  79.75\n",
            "Learning rate after initialization:  0.0026569762988232814\n",
            "Trainloss at epoch 24: 0.038055136597617285\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  81.25\n",
            "Learning rate after initialization:  0.0024999999999999966\n",
            "Trainloss at epoch 25: 0.03155499678350201\n",
            "Train intent accuracy:  99.33333333333333\n",
            "Valid intent accuracy:  82.5\n",
            "Learning rate after initialization:  0.002343023701176713\n",
            "Trainloss at epoch 26: 0.015008775875781123\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.0021866669160892347\n",
            "Trainloss at epoch 27: 0.037965314040009523\n",
            "Train intent accuracy:  98.83333333333333\n",
            "Valid intent accuracy:  81.25\n",
            "Learning rate after initialization:  0.0020315467135356854\n",
            "Trainloss at epoch 28: 0.025811643060909484\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  81.5\n",
            "Learning rate after initialization:  0.0018782752820878596\n",
            "Trainloss at epoch 29: 0.016340108582210775\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  83.75\n",
            "Learning rate after initialization:  0.0017274575140626284\n",
            "Trainloss at epoch 30: 0.008275543319637348\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  83.5\n",
            "Learning rate after initialization:  0.001579688618288303\n",
            "Trainloss at epoch 31: 0.03416345548650593\n",
            "Train intent accuracy:  99.33333333333333\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.0014355517710873164\n",
            "Trainloss at epoch 32: 0.006876338383575019\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  83.0\n",
            "Learning rate after initialization:  0.0012956158147457105\n",
            "Trainloss at epoch 33: 0.02024707946417804\n",
            "Train intent accuracy:  99.58333333333333\n",
            "Valid intent accuracy:  82.5\n",
            "Learning rate after initialization:  0.0011604330125525072\n",
            "Trainloss at epoch 34: 0.018819448184283254\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  82.25\n",
            "Learning rate after initialization:  0.0010305368692688165\n",
            "Trainloss at epoch 35: 0.008995654899320615\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.0009064400256282751\n",
            "Trainloss at epoch 36: 0.006275250538142006\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  83.0\n",
            "Learning rate after initialization:  0.0007886322351782788\n",
            "Trainloss at epoch 37: 0.0065087910334113985\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  83.5\n",
            "Learning rate after initialization:  0.0006775784314464713\n",
            "Trainloss at epoch 38: 0.012348425647360273\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  82.5\n",
            "Learning rate after initialization:  0.000573716893060526\n",
            "Trainloss at epoch 39: 0.0037629074757109934\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  83.5\n",
            "Learning rate after initialization:  0.00047745751406263115\n",
            "Trainloss at epoch 40: 0.005418520085329778\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  0.0003891801862449619\n",
            "Trainloss at epoch 41: 0.0016809539412957076\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  84.75\n",
            "Learning rate after initialization:  0.0003092332998903412\n",
            "Trainloss at epoch 42: 0.003354067766371085\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  84.5\n",
            "Learning rate after initialization:  0.00023793236883495124\n",
            "Trainloss at epoch 43: 0.005605946579108652\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  83.5\n",
            "Learning rate after initialization:  0.00017555878527937096\n",
            "Trainloss at epoch 44: 0.0031109708064545167\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.00012235870926211593\n",
            "Trainloss at epoch 45: 0.0014973781584749783\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  83.75\n",
            "Learning rate after initialization:  7.854209717842218e-05\n",
            "Trainloss at epoch 46: 0.002105411541139658\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  4.4281873178278385e-05\n",
            "Trainloss at epoch 47: 0.007705751120642833\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  1.9713246713805553e-05\n",
            "Trainloss at epoch 48: 0.0010460203185702038\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  4.933178929321093e-06\n",
            "Trainloss at epoch 49: 0.0015476021381848688\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  0.0\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_v.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 86188850\n",
            "Number of trainable params of the model: 482354\n",
            "AST_LoRA(\n",
            "  (model): ASTModel_LoRA(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_LoRA(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_LoRA(\n",
            "          (attention): ASTAttention_LoRA(\n",
            "            (attention): ASTSelfAttention_LoRA(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "              (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_LoRA(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_LoRA(\n",
            "        (attention): ASTAttention_LoRA(\n",
            "          (attention): ASTSelfAttention_LoRA(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "            (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 2.4124172141677453\n",
            "Train intent accuracy:  37.5\n",
            "Valid intent accuracy:  58.5\n",
            "Learning rate after initialization:  0.004995066821070678\n",
            "Trainloss at epoch 1: 0.6810670393077951\n",
            "Train intent accuracy:  79.83333333333333\n",
            "Valid intent accuracy:  70.5\n",
            "Learning rate after initialization:  0.004980286753286194\n",
            "Trainloss at epoch 2: 0.43923217881666987\n",
            "Train intent accuracy:  86.33333333333333\n",
            "Valid intent accuracy:  74.5\n",
            "Learning rate after initialization:  0.004955718126821718\n",
            "Trainloss at epoch 3: 0.2401943877339363\n",
            "Train intent accuracy:  92.83333333333333\n",
            "Valid intent accuracy:  75.5\n",
            "Learning rate after initialization:  0.0049214579028215725\n",
            "Trainloss at epoch 4: 0.18293158406097637\n",
            "Train intent accuracy:  94.33333333333334\n",
            "Valid intent accuracy:  77.25\n",
            "Learning rate after initialization:  0.004877641290737876\n",
            "Trainloss at epoch 5: 0.17647859463958362\n",
            "Train intent accuracy:  94.58333333333333\n",
            "Valid intent accuracy:  77.5\n",
            "Learning rate after initialization:  0.004824441214720621\n",
            "Trainloss at epoch 6: 0.13646697846094244\n",
            "Train intent accuracy:  95.0\n",
            "Valid intent accuracy:  77.75\n",
            "Learning rate after initialization:  0.004762067631165042\n",
            "Trainloss at epoch 7: 0.14967233388635673\n",
            "Train intent accuracy:  95.33333333333334\n",
            "Valid intent accuracy:  79.75\n",
            "Learning rate after initialization:  0.0046907667001096515\n",
            "Trainloss at epoch 8: 0.14040101373470143\n",
            "Train intent accuracy:  96.0\n",
            "Valid intent accuracy:  79.25\n",
            "Learning rate after initialization:  0.004610819813755028\n",
            "Trainloss at epoch 9: 0.12358359983926148\n",
            "Train intent accuracy:  95.83333333333334\n",
            "Valid intent accuracy:  77.0\n",
            "Learning rate after initialization:  0.004522542485937359\n",
            "Trainloss at epoch 10: 0.1514522748460111\n",
            "Train intent accuracy:  95.41666666666667\n",
            "Valid intent accuracy:  80.5\n",
            "Learning rate after initialization:  0.0044262831069394664\n",
            "Trainloss at epoch 11: 0.09541598754003644\n",
            "Train intent accuracy:  97.66666666666667\n",
            "Valid intent accuracy:  81.75\n",
            "Learning rate after initialization:  0.004322421568553524\n",
            "Trainloss at epoch 12: 0.07551973006737076\n",
            "Train intent accuracy:  97.66666666666667\n",
            "Valid intent accuracy:  81.25\n",
            "Learning rate after initialization:  0.004211367764821718\n",
            "Trainloss at epoch 13: 0.09276552397855803\n",
            "Train intent accuracy:  96.83333333333334\n",
            "Valid intent accuracy:  80.25\n",
            "Learning rate after initialization:  0.0040935599743717205\n",
            "Trainloss at epoch 14: 0.06352922589959283\n",
            "Train intent accuracy:  98.16666666666667\n",
            "Valid intent accuracy:  80.25\n",
            "Learning rate after initialization:  0.00396946313073118\n",
            "Trainloss at epoch 15: 0.08490617555492606\n",
            "Train intent accuracy:  97.83333333333334\n",
            "Valid intent accuracy:  79.0\n",
            "Learning rate after initialization:  0.003839566987447489\n",
            "Trainloss at epoch 16: 0.06480686482973397\n",
            "Train intent accuracy:  98.16666666666667\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.003704384185254285\n",
            "Trainloss at epoch 17: 0.053888063307998606\n",
            "Train intent accuracy:  98.83333333333333\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.003564448228912676\n",
            "Trainloss at epoch 18: 0.03680201747920364\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  83.75\n",
            "Learning rate after initialization:  0.003420311381711691\n",
            "Trainloss at epoch 19: 0.055094092722835115\n",
            "Train intent accuracy:  98.5\n",
            "Valid intent accuracy:  82.5\n",
            "Learning rate after initialization:  0.0032725424859373652\n",
            "Trainloss at epoch 20: 0.05557745155927382\n",
            "Train intent accuracy:  98.5\n",
            "Valid intent accuracy:  82.75\n",
            "Learning rate after initialization:  0.003121724717912136\n",
            "Trainloss at epoch 21: 0.03740059227780684\n",
            "Train intent accuracy:  99.16666666666667\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.00296845328646431\n",
            "Trainloss at epoch 22: 0.02369387281023113\n",
            "Train intent accuracy:  99.58333333333333\n",
            "Valid intent accuracy:  85.5\n",
            "Learning rate after initialization:  0.002813333083910759\n",
            "Trainloss at epoch 23: 0.021672190258916663\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  84.75\n",
            "Learning rate after initialization:  0.0026569762988232814\n",
            "Trainloss at epoch 24: 0.02727016438515612\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.0024999999999999966\n",
            "Trainloss at epoch 25: 0.019786424431674134\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.002343023701176713\n",
            "Trainloss at epoch 26: 0.02596755510373776\n",
            "Train intent accuracy:  99.16666666666667\n",
            "Valid intent accuracy:  84.75\n",
            "Learning rate after initialization:  0.0021866669160892347\n",
            "Trainloss at epoch 27: 0.02306561989672972\n",
            "Train intent accuracy:  99.5\n",
            "Valid intent accuracy:  85.25\n",
            "Learning rate after initialization:  0.0020315467135356854\n",
            "Trainloss at epoch 28: 0.017538589281397628\n",
            "Train intent accuracy:  99.5\n",
            "Valid intent accuracy:  86.0\n",
            "Learning rate after initialization:  0.0018782752820878596\n",
            "Trainloss at epoch 29: 0.01554189368739332\n",
            "Train intent accuracy:  99.5\n",
            "Valid intent accuracy:  87.0\n",
            "Learning rate after initialization:  0.0017274575140626284\n",
            "Trainloss at epoch 30: 0.02303871768220377\n",
            "Train intent accuracy:  99.16666666666667\n",
            "Valid intent accuracy:  86.5\n",
            "Learning rate after initialization:  0.001579688618288303\n",
            "Trainloss at epoch 31: 0.01739019224355855\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  86.5\n",
            "Learning rate after initialization:  0.0014355517710873164\n",
            "Trainloss at epoch 32: 0.020356069294441687\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.0012956158147457105\n",
            "Trainloss at epoch 33: 0.006449768955414919\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  89.0\n",
            "Learning rate after initialization:  0.0011604330125525072\n",
            "Trainloss at epoch 34: 0.008098044705356619\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  88.5\n",
            "Learning rate after initialization:  0.0010305368692688165\n",
            "Trainloss at epoch 35: 0.002098424092094463\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.0009064400256282751\n",
            "Trainloss at epoch 36: 0.002834331613006438\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  88.5\n",
            "Learning rate after initialization:  0.0007886322351782788\n",
            "Trainloss at epoch 37: 0.010330711798910909\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.0006775784314464713\n",
            "Trainloss at epoch 38: 0.003860033073578961\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.000573716893060526\n",
            "Trainloss at epoch 39: 0.004547273230089463\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.00047745751406263115\n",
            "Trainloss at epoch 40: 0.007667808198771366\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  88.25\n",
            "Learning rate after initialization:  0.0003891801862449619\n",
            "Trainloss at epoch 41: 0.0011138013452230218\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.75\n",
            "Learning rate after initialization:  0.0003092332998903412\n",
            "Trainloss at epoch 42: 0.0009497391430685591\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  89.25\n",
            "Learning rate after initialization:  0.00023793236883495124\n",
            "Trainloss at epoch 43: 0.0015786819709127915\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  88.5\n",
            "Learning rate after initialization:  0.00017555878527937096\n",
            "Trainloss at epoch 44: 0.004146878592636264\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  89.5\n",
            "Learning rate after initialization:  0.00012235870926211593\n",
            "Trainloss at epoch 45: 0.0061340570142707105\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  89.25\n",
            "Learning rate after initialization:  7.854209717842218e-05\n",
            "Trainloss at epoch 46: 0.00803362674732374\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  89.0\n",
            "Learning rate after initialization:  4.4281873178278385e-05\n",
            "Trainloss at epoch 47: 0.002424669996559571\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  89.0\n",
            "Learning rate after initialization:  1.9713246713805553e-05\n",
            "Trainloss at epoch 48: 0.0017783597198247566\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  89.0\n",
            "Learning rate after initialization:  4.933178929321093e-06\n",
            "Trainloss at epoch 49: 0.0020223359380523967\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  89.0\n",
            "Learning rate after initialization:  0.0\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized: ['audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.0.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.1.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.10.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.11.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.2.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.3.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.4.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.5.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.6.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.7.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.8.attention.attention.lora_up_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_down_v.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_q.weight', 'audio_spectrogram_transformer.encoder.layer.9.attention.attention.lora_up_v.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of ASTModel_LoRA were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
            "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Number of params of the model: 86188850\n",
            "Number of trainable params of the model: 482354\n",
            "AST_LoRA(\n",
            "  (model): ASTModel_LoRA(\n",
            "    (embeddings): ASTEmbeddings(\n",
            "      (patch_embeddings): ASTPatchEmbeddings(\n",
            "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ASTEncoder_LoRA(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ASTLayer_LoRA(\n",
            "          (attention): ASTAttention_LoRA(\n",
            "            (attention): ASTSelfAttention_LoRA(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "              (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "              (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "            )\n",
            "            (output): ASTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ASTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ASTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (embeddings): ASTEmbeddings(\n",
            "    (patch_embeddings): ASTPatchEmbeddings(\n",
            "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (encoder): ASTEncoder_LoRA(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x ASTLayer_LoRA(\n",
            "        (attention): ASTAttention_LoRA(\n",
            "          (attention): ASTSelfAttention_LoRA(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (lora_down_q): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_q): Linear(in_features=12, out_features=768, bias=False)\n",
            "            (lora_down_v): Linear(in_features=768, out_features=12, bias=False)\n",
            "            (lora_up_v): Linear(in_features=12, out_features=768, bias=False)\n",
            "          )\n",
            "          (output): ASTSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): ASTIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): ASTOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  (classification_head): Linear(in_features=768, out_features=50, bias=True)\n",
            ")\n",
            "Start training for 50 epochs\n",
            "Trainloss at epoch 0: 2.3491480946540833\n",
            "Train intent accuracy:  41.75\n",
            "Valid intent accuracy:  67.0\n",
            "Learning rate after initialization:  0.004995066821070678\n",
            "Trainloss at epoch 1: 0.6101696938276291\n",
            "Train intent accuracy:  82.0\n",
            "Valid intent accuracy:  75.25\n",
            "Learning rate after initialization:  0.004980286753286194\n",
            "Trainloss at epoch 2: 0.3490826344411624\n",
            "Train intent accuracy:  89.16666666666667\n",
            "Valid intent accuracy:  74.75\n",
            "Learning rate after initialization:  0.004955718126821718\n",
            "Trainloss at epoch 3: 0.27552962391392183\n",
            "Train intent accuracy:  92.08333333333333\n",
            "Valid intent accuracy:  76.25\n",
            "Learning rate after initialization:  0.0049214579028215725\n",
            "Trainloss at epoch 4: 0.21361798930325007\n",
            "Train intent accuracy:  94.08333333333333\n",
            "Valid intent accuracy:  76.0\n",
            "Learning rate after initialization:  0.004877641290737876\n",
            "Trainloss at epoch 5: 0.14212863416852137\n",
            "Train intent accuracy:  95.58333333333333\n",
            "Valid intent accuracy:  79.75\n",
            "Learning rate after initialization:  0.004824441214720621\n",
            "Trainloss at epoch 6: 0.18678315209322854\n",
            "Train intent accuracy:  93.58333333333333\n",
            "Valid intent accuracy:  78.0\n",
            "Learning rate after initialization:  0.004762067631165042\n",
            "Trainloss at epoch 7: 0.151605729895987\n",
            "Train intent accuracy:  95.41666666666667\n",
            "Valid intent accuracy:  77.5\n",
            "Learning rate after initialization:  0.0046907667001096515\n",
            "Trainloss at epoch 8: 0.1342981488345877\n",
            "Train intent accuracy:  95.41666666666667\n",
            "Valid intent accuracy:  79.5\n",
            "Learning rate after initialization:  0.004610819813755028\n",
            "Trainloss at epoch 9: 0.11026658438832353\n",
            "Train intent accuracy:  97.16666666666667\n",
            "Valid intent accuracy:  82.25\n",
            "Learning rate after initialization:  0.004522542485937359\n",
            "Trainloss at epoch 10: 0.11961458280290428\n",
            "Train intent accuracy:  96.75\n",
            "Valid intent accuracy:  82.75\n",
            "Learning rate after initialization:  0.0044262831069394664\n",
            "Trainloss at epoch 11: 0.10181431364464133\n",
            "Train intent accuracy:  97.0\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.004322421568553524\n",
            "Trainloss at epoch 12: 0.059186113593903814\n",
            "Train intent accuracy:  98.41666666666666\n",
            "Valid intent accuracy:  83.75\n",
            "Learning rate after initialization:  0.004211367764821718\n",
            "Trainloss at epoch 13: 0.09948863875194404\n",
            "Train intent accuracy:  96.91666666666666\n",
            "Valid intent accuracy:  80.75\n",
            "Learning rate after initialization:  0.0040935599743717205\n",
            "Trainloss at epoch 14: 0.0577083083274039\n",
            "Train intent accuracy:  98.41666666666666\n",
            "Valid intent accuracy:  83.0\n",
            "Learning rate after initialization:  0.00396946313073118\n",
            "Trainloss at epoch 15: 0.059925269053660725\n",
            "Train intent accuracy:  98.83333333333333\n",
            "Valid intent accuracy:  82.0\n",
            "Learning rate after initialization:  0.003839566987447489\n",
            "Trainloss at epoch 16: 0.05312819283235034\n",
            "Train intent accuracy:  98.5\n",
            "Valid intent accuracy:  80.0\n",
            "Learning rate after initialization:  0.003704384185254285\n",
            "Trainloss at epoch 17: 0.08199124035768603\n",
            "Train intent accuracy:  97.16666666666667\n",
            "Valid intent accuracy:  81.0\n",
            "Learning rate after initialization:  0.003564448228912676\n",
            "Trainloss at epoch 18: 0.04591529000869119\n",
            "Train intent accuracy:  99.0\n",
            "Valid intent accuracy:  84.5\n",
            "Learning rate after initialization:  0.003420311381711691\n",
            "Trainloss at epoch 19: 0.044654785888269544\n",
            "Train intent accuracy:  98.66666666666667\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.0032725424859373652\n",
            "Trainloss at epoch 20: 0.0731575725826827\n",
            "Train intent accuracy:  97.83333333333334\n",
            "Valid intent accuracy:  82.75\n",
            "Learning rate after initialization:  0.003121724717912136\n",
            "Trainloss at epoch 21: 0.056665261616121586\n",
            "Train intent accuracy:  98.75\n",
            "Valid intent accuracy:  85.75\n",
            "Learning rate after initialization:  0.00296845328646431\n",
            "Trainloss at epoch 22: 0.05440834114377044\n",
            "Train intent accuracy:  98.25\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.002813333083910759\n",
            "Trainloss at epoch 23: 0.026031656276532693\n",
            "Train intent accuracy:  99.16666666666667\n",
            "Valid intent accuracy:  82.5\n",
            "Learning rate after initialization:  0.0026569762988232814\n",
            "Trainloss at epoch 24: 0.023372189601344105\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  0.0024999999999999966\n",
            "Trainloss at epoch 25: 0.022767287948609966\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  83.75\n",
            "Learning rate after initialization:  0.002343023701176713\n",
            "Trainloss at epoch 26: 0.019466559926513582\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  83.5\n",
            "Learning rate after initialization:  0.0021866669160892347\n",
            "Trainloss at epoch 27: 0.009889766849626443\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  83.25\n",
            "Learning rate after initialization:  0.0020315467135356854\n",
            "Trainloss at epoch 28: 0.029718082171472673\n",
            "Train intent accuracy:  99.25\n",
            "Valid intent accuracy:  84.75\n",
            "Learning rate after initialization:  0.0018782752820878596\n",
            "Trainloss at epoch 29: 0.018669872431354106\n",
            "Train intent accuracy:  99.41666666666666\n",
            "Valid intent accuracy:  86.0\n",
            "Learning rate after initialization:  0.0017274575140626284\n",
            "Trainloss at epoch 30: 0.025189986847659673\n",
            "Train intent accuracy:  99.33333333333333\n",
            "Valid intent accuracy:  84.25\n",
            "Learning rate after initialization:  0.001579688618288303\n",
            "Trainloss at epoch 31: 0.0069480455927795875\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  84.5\n",
            "Learning rate after initialization:  0.0014355517710873164\n",
            "Trainloss at epoch 32: 0.012206397537068514\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  85.0\n",
            "Learning rate after initialization:  0.0012956158147457105\n",
            "Trainloss at epoch 33: 0.010283062824256424\n",
            "Train intent accuracy:  99.75\n",
            "Valid intent accuracy:  84.5\n",
            "Learning rate after initialization:  0.0011604330125525072\n",
            "Trainloss at epoch 34: 0.005717427405455199\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  84.0\n",
            "Learning rate after initialization:  0.0010305368692688165\n",
            "Trainloss at epoch 35: 0.010585346371762602\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  85.0\n",
            "Learning rate after initialization:  0.0009064400256282751\n",
            "Trainloss at epoch 36: 0.011269390527511285\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  86.25\n",
            "Learning rate after initialization:  0.0007886322351782788\n",
            "Trainloss at epoch 37: 0.005837738967353576\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.25\n",
            "Learning rate after initialization:  0.0006775784314464713\n",
            "Trainloss at epoch 38: 0.0060110951438362365\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.000573716893060526\n",
            "Trainloss at epoch 39: 0.0015849238081596252\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  86.75\n",
            "Learning rate after initialization:  0.00047745751406263115\n",
            "Trainloss at epoch 40: 0.016874366284786158\n",
            "Train intent accuracy:  99.66666666666667\n",
            "Valid intent accuracy:  87.25\n",
            "Learning rate after initialization:  0.0003891801862449619\n",
            "Trainloss at epoch 41: 0.0015700830293721275\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  87.0\n",
            "Learning rate after initialization:  0.0003092332998903412\n",
            "Trainloss at epoch 42: 0.0036030777729664757\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.0\n",
            "Learning rate after initialization:  0.00023793236883495124\n",
            "Trainloss at epoch 43: 0.00568885324403374\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.00017555878527937096\n",
            "Trainloss at epoch 44: 0.007237199830629642\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  87.75\n",
            "Learning rate after initialization:  0.00012235870926211593\n",
            "Trainloss at epoch 45: 0.007119753538925005\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  87.5\n",
            "Learning rate after initialization:  7.854209717842218e-05\n",
            "Trainloss at epoch 46: 0.0038982578331151195\n",
            "Train intent accuracy:  99.83333333333333\n",
            "Valid intent accuracy:  87.5\n",
            "Learning rate after initialization:  4.4281873178278385e-05\n",
            "Trainloss at epoch 47: 0.003317856243244789\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.25\n",
            "Learning rate after initialization:  1.9713246713805553e-05\n",
            "Trainloss at epoch 48: 0.004114274962998216\n",
            "Train intent accuracy:  99.91666666666667\n",
            "Valid intent accuracy:  87.25\n",
            "Learning rate after initialization:  4.933178929321093e-06\n",
            "Trainloss at epoch 49: 0.0008286976375721247\n",
            "Train intent accuracy:  100.0\n",
            "Valid intent accuracy:  87.25\n",
            "Learning rate after initialization:  0.0\n",
            "Folds accuracy:  [0.87, 0.845, 0.85, 0.87, 0.855]\n",
            "Avg accuracy over the 5 fold(s):  0.858\n",
            "Std accuracy over the 5 fold(s):  0.01029563014098701\n",
            "Training time 4:39:21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yt9Y__jNfMj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}